{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model devepment\n",
    "\n",
    "In this document we develop and compare different models for our model devepment. We have the following sections:\n",
    "\n",
    "1. Model creation\n",
    "2. Model evaluation\n",
    "3. Model implementation on test data\n",
    "\n",
    "Note that for model creation instead of running the code each time one can load the best model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import preprocessor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import make_scorer, roc_auc_score, recall_score\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from scipy.stats import uniform, randint\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been loaded\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "total_df = pd.read_csv('../Data/Base.csv')\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = total_df.drop(columns=['fraud_bool'])\n",
    "y = total_df['fraud_bool']\n",
    "\n",
    "# Split the data into training and test sets using stratified sampling\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "print(\"Data has been loaded\")\n",
    "\n",
    "# Apply the preprocessor to the training and test datasets\n",
    "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "X_test_preprocessed = preprocessor.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Model Creation\n",
    "\n",
    "### 1a. Hyperparameter specification\n",
    "\n",
    "We will use the following hyperparameters for our models. They are based on common hyperparameters used for the respective models with ranges that are commonly used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline with placeholder classifier\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', LogisticRegression())])\n",
    "\n",
    "# Define models and hyperparameters\n",
    "models = {\n",
    "    'Logistic Regression (lbfgs)': (\n",
    "        LogisticRegression(class_weight='balanced', random_state=42, max_iter=1000),\n",
    "        {\n",
    "            'classifier__C': uniform(0.01, 10),  # Regularization strength\n",
    "            'classifier__solver': ['lbfgs'],  # Only lbfgs solver\n",
    "            'classifier__penalty': ['l2', 'none'],  # Supported penalties\n",
    "        }\n",
    "    ),\n",
    "    # 'Logistic Regression (liblinear)': (\n",
    "    #     LogisticRegression(class_weight='balanced', random_state=42, max_iter=1000),\n",
    "    #     {\n",
    "    #         'classifier__C': uniform(0.01, 10),  # Regularization strength\n",
    "    #         'classifier__solver': ['liblinear'],  # Only liblinear solver\n",
    "    #         'classifier__penalty': ['l1', 'l2'],  # Supported penalties\n",
    "    #     }\n",
    "    # ),\n",
    "    # 'Logistic Regression (saga)': (\n",
    "    #     LogisticRegression(class_weight='balanced', random_state=42, max_iter=1000),\n",
    "    #     {\n",
    "    #         'classifier__C': uniform(0.01, 10),  # Regularization strength\n",
    "    #         'classifier__solver': ['saga'],  # Only saga solver\n",
    "    #         'classifier__penalty': ['l1', 'l2', 'elasticnet', 'none'],  # All supported penalties\n",
    "    #         'classifier__l1_ratio': uniform(0, 1),  # ElasticNet mixing parameter (only with saga and elasticnet)\n",
    "    #     }\n",
    "    # ),\n",
    "    'Logistic Regression (default)': (\n",
    "        LogisticRegression(class_weight='balanced', random_state=42, max_iter=1000),\n",
    "        {\n",
    "            'classifier__C': uniform(0.01, 10),  # Regularization strength\n",
    "        }\n",
    "    ),\n",
    "    'Random Forest': (\n",
    "        RandomForestClassifier(class_weight='balanced', random_state=42),\n",
    "        {\n",
    "            'classifier__n_estimators': randint(100, 300),  # Number of trees\n",
    "            'classifier__max_depth': randint(5, 20),  # Max tree depth\n",
    "            'classifier__min_samples_split': randint(2, 10),  # Min samples to split\n",
    "            'classifier__min_samples_leaf': randint(1, 5),  # Min samples per leaf\n",
    "            'classifier__class_weight': ['balanced', {0: 1, 1: 10}],  # Explicit weights\n",
    "        }\n",
    "    ),\n",
    "    'Gradient Boosting': (\n",
    "        GradientBoostingClassifier(random_state=42),\n",
    "        {\n",
    "            'classifier__n_estimators': randint(50, 300),  # Number of boosting stages\n",
    "            'classifier__learning_rate': uniform(0.01, 0.2),  # Shrinkage rate\n",
    "            'classifier__max_depth': randint(3, 15),  # Max tree depth\n",
    "            'classifier__min_samples_split': randint(2, 10),  # Min samples to split\n",
    "            'classifier__min_samples_leaf': randint(1, 5),  # Min samples per leaf\n",
    "        }\n",
    "    ),\n",
    "    'XGBoost': (\n",
    "        XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss', tree_method='gpu_hist'),\n",
    "        {\n",
    "            'classifier__n_estimators': randint(50, 300),  # Number of boosting stages\n",
    "            'classifier__learning_rate': uniform(0.01, 0.2),  # Learning rate\n",
    "            'classifier__max_depth': randint(3, 15),  # Maximum tree depth\n",
    "            'classifier__gamma': uniform(0, 0.5),  # Min split loss\n",
    "            'classifier__scale_pos_weight': [1, 5, 10, 20],  # Reweighting for imbalanced data\n",
    "        }\n",
    "    ),\n",
    "    'LightGBM': (\n",
    "        LGBMClassifier(random_state=42, device='gpu'),\n",
    "        {\n",
    "            'classifier__n_estimators': randint(50, 300),  # Number of boosting stages\n",
    "            'classifier__learning_rate': uniform(0.01, 0.2),  # Learning rate\n",
    "            'classifier__max_depth': randint(3, 15),  # Maximum tree depth\n",
    "            'classifier__num_leaves': randint(20, 50),  # Number of leaves\n",
    "            'classifier__class_weight': ['balanced', {0: 1, 1: 10}],  # Explicit weights\n",
    "        }\n",
    "    ),\n",
    "    'Naive Bayes': (\n",
    "        GaussianNB(),\n",
    "        {}  # No hyperparameters for Naive Bayes\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b. Exploratory Hyperparameter Search \n",
    "\n",
    "To find the best hyperparameters for each model we will use RandomizedSearchCV because it is more efficient than GridSearchCV for the exploration of the hyperparameter space.\n",
    "\n",
    "Note: Running the following code is not recommended. It is just for reference. Running it will train the models, and we have provided our training mnodels in the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gamacore/FINAL/Bank-Fraud-Detection/bank/lib/python3.10/site-packages/sklearn/metrics/_scorer.py:610: FutureWarning: The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting RandomizedSearchCV for Logistic Regression (lbfgs) ---\n",
      "\n",
      "Model Logistic Regression (lbfgs) already trained. Skipping...\n",
      "\n",
      "--- Starting RandomizedSearchCV for Logistic Regression (default) ---\n",
      "\n",
      "Model Logistic Regression (default) already trained. Skipping...\n",
      "\n",
      "--- Starting RandomizedSearchCV for Random Forest ---\n",
      "\n",
      "Fitting the model Random Forest with 5 iterations and 5 cross-validation splits...\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "[CV 1/5] END classifier__class_weight=balanced, classifier__max_depth=8, classifier__min_samples_leaf=1, classifier__min_samples_split=8, classifier__n_estimators=206;, score=0.458 total time= 1.9min\n",
      "[CV 2/5] END classifier__class_weight=balanced, classifier__max_depth=8, classifier__min_samples_leaf=1, classifier__min_samples_split=8, classifier__n_estimators=206;, score=0.459 total time= 1.9min\n",
      "[CV 3/5] END classifier__class_weight=balanced, classifier__max_depth=8, classifier__min_samples_leaf=1, classifier__min_samples_split=8, classifier__n_estimators=206;, score=0.453 total time= 1.9min\n",
      "[CV 4/5] END classifier__class_weight=balanced, classifier__max_depth=8, classifier__min_samples_leaf=1, classifier__min_samples_split=8, classifier__n_estimators=206;, score=0.453 total time= 1.9min\n",
      "[CV 5/5] END classifier__class_weight=balanced, classifier__max_depth=8, classifier__min_samples_leaf=1, classifier__min_samples_split=8, classifier__n_estimators=206;, score=0.464 total time= 1.9min\n",
      "[CV 1/5] END classifier__class_weight={0: 1, 1: 10}, classifier__max_depth=17, classifier__min_samples_leaf=1, classifier__min_samples_split=8, classifier__n_estimators=221;, score=0.487 total time= 2.9min\n",
      "[CV 2/5] END classifier__class_weight={0: 1, 1: 10}, classifier__max_depth=17, classifier__min_samples_leaf=1, classifier__min_samples_split=8, classifier__n_estimators=221;, score=0.484 total time= 2.9min\n",
      "[CV 3/5] END classifier__class_weight={0: 1, 1: 10}, classifier__max_depth=17, classifier__min_samples_leaf=1, classifier__min_samples_split=8, classifier__n_estimators=221;, score=0.475 total time= 2.9min\n",
      "[CV 4/5] END classifier__class_weight={0: 1, 1: 10}, classifier__max_depth=17, classifier__min_samples_leaf=1, classifier__min_samples_split=8, classifier__n_estimators=221;, score=0.486 total time= 3.0min\n",
      "[CV 5/5] END classifier__class_weight={0: 1, 1: 10}, classifier__max_depth=17, classifier__min_samples_leaf=1, classifier__min_samples_split=8, classifier__n_estimators=221;, score=0.499 total time= 3.0min\n",
      "[CV 1/5] END classifier__class_weight=balanced, classifier__max_depth=11, classifier__min_samples_leaf=3, classifier__min_samples_split=4, classifier__n_estimators=187;, score=0.468 total time= 2.1min\n",
      "[CV 2/5] END classifier__class_weight=balanced, classifier__max_depth=11, classifier__min_samples_leaf=3, classifier__min_samples_split=4, classifier__n_estimators=187;, score=0.463 total time= 2.1min\n",
      "[CV 3/5] END classifier__class_weight=balanced, classifier__max_depth=11, classifier__min_samples_leaf=3, classifier__min_samples_split=4, classifier__n_estimators=187;, score=0.455 total time= 2.1min\n",
      "[CV 4/5] END classifier__class_weight=balanced, classifier__max_depth=11, classifier__min_samples_leaf=3, classifier__min_samples_split=4, classifier__n_estimators=187;, score=0.461 total time= 2.1min\n",
      "[CV 5/5] END classifier__class_weight=balanced, classifier__max_depth=11, classifier__min_samples_leaf=3, classifier__min_samples_split=4, classifier__n_estimators=187;, score=0.480 total time= 2.1min\n",
      "[CV 1/5] END classifier__class_weight=balanced, classifier__max_depth=8, classifier__min_samples_leaf=4, classifier__min_samples_split=9, classifier__n_estimators=230;, score=0.457 total time= 2.3min\n",
      "[CV 2/5] END classifier__class_weight=balanced, classifier__max_depth=8, classifier__min_samples_leaf=4, classifier__min_samples_split=9, classifier__n_estimators=230;, score=0.455 total time= 2.1min\n",
      "[CV 3/5] END classifier__class_weight=balanced, classifier__max_depth=8, classifier__min_samples_leaf=4, classifier__min_samples_split=9, classifier__n_estimators=230;, score=0.454 total time= 2.1min\n",
      "[CV 4/5] END classifier__class_weight=balanced, classifier__max_depth=8, classifier__min_samples_leaf=4, classifier__min_samples_split=9, classifier__n_estimators=230;, score=0.454 total time= 2.1min\n",
      "[CV 5/5] END classifier__class_weight=balanced, classifier__max_depth=8, classifier__min_samples_leaf=4, classifier__min_samples_split=9, classifier__n_estimators=230;, score=0.467 total time= 2.1min\n",
      "[CV 1/5] END classifier__class_weight={0: 1, 1: 10}, classifier__max_depth=9, classifier__min_samples_leaf=2, classifier__min_samples_split=9, classifier__n_estimators=257;, score=0.463 total time= 2.5min\n",
      "[CV 2/5] END classifier__class_weight={0: 1, 1: 10}, classifier__max_depth=9, classifier__min_samples_leaf=2, classifier__min_samples_split=9, classifier__n_estimators=257;, score=0.470 total time= 2.5min\n",
      "[CV 3/5] END classifier__class_weight={0: 1, 1: 10}, classifier__max_depth=9, classifier__min_samples_leaf=2, classifier__min_samples_split=9, classifier__n_estimators=257;, score=0.467 total time= 2.5min\n",
      "[CV 4/5] END classifier__class_weight={0: 1, 1: 10}, classifier__max_depth=9, classifier__min_samples_leaf=2, classifier__min_samples_split=9, classifier__n_estimators=257;, score=0.473 total time= 2.5min\n",
      "[CV 5/5] END classifier__class_weight={0: 1, 1: 10}, classifier__max_depth=9, classifier__min_samples_leaf=2, classifier__min_samples_split=9, classifier__n_estimators=257;, score=0.477 total time= 2.5min\n",
      "\n",
      "--- Finished RandomizedSearchCV for Random Forest in 3690.86s ---\n",
      "\n",
      "Saving RandomizedSearchCV results for Random Forest as saved_models/Random Forest_2024-12-08_20-15-00_3690.86s.joblib...\n",
      "\n",
      "RandomizedSearchCV for Random Forest saved successfully.\n",
      "\n",
      "\n",
      "--- Starting RandomizedSearchCV for Gradient Boosting ---\n",
      "\n",
      "Fitting the model Gradient Boosting with 5 iterations and 5 cross-validation splits...\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "[CV 1/5] END classifier__learning_rate=0.0849080237694725, classifier__max_depth=13, classifier__min_samples_leaf=4, classifier__min_samples_split=6, classifier__n_estimators=70;, score=0.431 total time= 7.6min\n",
      "[CV 2/5] END classifier__learning_rate=0.0849080237694725, classifier__max_depth=13, classifier__min_samples_leaf=4, classifier__min_samples_split=6, classifier__n_estimators=70;, score=0.423 total time= 7.6min\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import joblib\n",
    "import os\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm # Progress bar\n",
    "from glob import glob # File search\n",
    "\n",
    "# Custom recall scorer at a target FPR threshold\n",
    "def recall_at_fpr(y_true, y_scores, target_fpr=0.05):\n",
    "    from sklearn.metrics import roc_curve\n",
    "    import numpy as np\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n",
    "    if len(np.where(fpr <= target_fpr)[0]) == 0:\n",
    "        # If no threshold meets the target FPR\n",
    "        return 0.0\n",
    "    threshold_idx = np.where(fpr <= target_fpr)[0][-1]\n",
    "    return tpr[threshold_idx]\n",
    "\n",
    "# Wrapper function to pass the target FPR\n",
    "def recall_at_fpr_scorer(y_true, y_scores):\n",
    "    return recall_at_fpr(y_true, y_scores, target_fpr=0.05)\n",
    "\n",
    "# Make a scorer for recall @ 5% FPR\n",
    "recall_5_fpr_scorer = make_scorer(recall_at_fpr_scorer, greater_is_better=True, needs_proba=True)\n",
    "\n",
    "# Create directory for saving models if it doesn't exist\n",
    "os.makedirs('saved_models', exist_ok=True)\n",
    "\n",
    "# Stratified K-Fold Cross-Validation\n",
    "stratified_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Number of random searches per model\n",
    "n_iter_per_model = 5\n",
    "best_models = []\n",
    "\n",
    "# Dictionary to store all RandomizedSearchCV objects\n",
    "search_results = {}\n",
    "\n",
    "# Iterate through each model\n",
    "for name, (model, params) in models.items():\n",
    "    print(f\"\\n--- Starting RandomizedSearchCV for {name} ---\\n\")\n",
    "    \n",
    "    # Check if the model has already been trained and skip if it exists\n",
    "    saved_files = glob(f\"saved_models/{name}_*.joblib\")\n",
    "    if saved_files:\n",
    "        print(f\"Model {name} already trained. Skipping...\")\n",
    "        continue\n",
    "\n",
    "    # Create pipeline\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', model)])\n",
    "\n",
    "    # Create RandomizedSearchCV\n",
    "    search = RandomizedSearchCV(\n",
    "        pipeline, \n",
    "        param_distributions=params,\n",
    "        n_iter=n_iter_per_model,\n",
    "        cv=stratified_cv,\n",
    "        n_jobs=1,\n",
    "        random_state=42,\n",
    "        scoring=recall_5_fpr_scorer,\n",
    "        verbose=3\n",
    "    )\n",
    "\n",
    "    # Start timing\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Fit the model\n",
    "    try:\n",
    "        print(f\"Fitting the model {name} with {n_iter_per_model} iterations and {stratified_cv.get_n_splits()} cross-validation splits...\")\n",
    "        search.fit(X_train, y_train)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while fitting {name}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # End timing\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Calculate elapsed time\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_time_str = f\"{elapsed_time:.2f}s\"\n",
    "    print(f\"\\n--- Finished RandomizedSearchCV for {name} in {elapsed_time_str} ---\\n\")\n",
    "\n",
    "    # Store the search object in the dictionary\n",
    "    search_results[name] = search\n",
    "\n",
    "    # Get current date and time for naming\n",
    "    current_datetime = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "    # Create a unique filename with version number, model name, date, and training time\n",
    "    filename = f\"saved_models/{name}_{current_datetime}_{elapsed_time_str}.joblib\"\n",
    "    \n",
    "    # Save each RandomizedSearchCV object immediately after training\n",
    "    print(f\"Saving RandomizedSearchCV results for {name} as {filename}...\\n\")\n",
    "    joblib.dump(search, filename)\n",
    "    print(f\"RandomizedSearchCV for {name} saved successfully.\\n\")\n",
    "\n",
    "print(\"\\n--- All Models Processed ---\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1c. Search saving and loading\n",
    "\n",
    "Save search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory containing the saved joblib files\n",
    "saved_models_dir = 'saved_models'\n",
    "\n",
    "# Initialize the final search_results dictionary to store all models\n",
    "search_results = {}\n",
    "\n",
    "# Iterate over each joblib file in the directory\n",
    "for filename in os.listdir(saved_models_dir):\n",
    "    if filename.endswith(\".joblib\"):\n",
    "        # Construct the full path to the file\n",
    "        filepath = os.path.join(saved_models_dir, filename)\n",
    "\n",
    "        # Load the model information from the file\n",
    "        model_info = joblib.load(filepath)\n",
    "\n",
    "        # Use the filename (without extension) as the key in the search_results dictionary\n",
    "        model_key = filename.replace('.joblib', '')\n",
    "        \n",
    "        # Add the loaded model information to the search_results dictionary\n",
    "        search_results[model_key] = model_info\n",
    "\n",
    "# Save the combined search_results dictionary to a new joblib file\n",
    "combined_filename = 'search_results.joblib'\n",
    "joblib.dump(search_results, combined_filename)\n",
    "print(f\"Combined search results saved successfully as {combined_filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results = joblib.load(f\"search_results.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model evaluation\n",
    "\n",
    "### 2a. Random search evaluation\n",
    "\n",
    "Due to the biased data set we use the auc roc score to evaluate different models. We start by printing the best model of each model class for our search. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list for storing model information\n",
    "results_summary = []\n",
    "\n",
    "# Collect the best model, score, and parameters\n",
    "for model_name, search in search_results.items():\n",
    "    best_score = search.best_score_\n",
    "    best_params = search.best_params_\n",
    "    results_summary.append({\n",
    "        'Model': model_name,\n",
    "        'Best Score (AUC)': f\"{best_score:.4f}\",\n",
    "        'Best Parameters': best_params\n",
    "    })\n",
    "\n",
    "# Convert to a DataFrame and sort by AUC score\n",
    "results_df = pd.DataFrame(results_summary).sort_values(by='Best Score (AUC)', ascending=False)\n",
    "\n",
    "# Display the DataFrame in Jupyter\n",
    "from IPython.display import display\n",
    "\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the best performing model on the trainig data is \"TODO\" with auc_roc score being \"TODO\". Now we will evaluate this model closer in the following section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2b. Best model evaluation\n",
    "\n",
    "We begin the evaluation of the best model by extracting it from search_results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize variables to track the best model\n",
    "best_model_name = None\n",
    "best_model_score = -float('inf')\n",
    "best_model_params = None\n",
    "best_model_object = None\n",
    "best_classifier = None\n",
    "\n",
    "# Iterate through the search results to find the best model\n",
    "for model_name, search in search_results.items():\n",
    "    if search.best_score_ > best_model_score:\n",
    "        best_model_name = model_name\n",
    "        best_model_score = search.best_score_\n",
    "        best_model_params = search.best_params_\n",
    "        best_model_object = search.best_estimator_\n",
    "\n",
    "        # Extract the classifier from the pipeline\n",
    "        best_classifier = best_model_object.named_steps['classifier']\n",
    "\n",
    "# Print the best model details\n",
    "print(f\"Best Model Name: {best_model_name}\")\n",
    "print(f\"Best Model Score (AUC): {best_model_score:.4f}\")\n",
    "print(f\"Best Model Parameters: {best_model_params}\")\n",
    "\n",
    "# Print the best classifier object\n",
    "print(f\"Best Classifier Object: {best_classifier}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continued Model Development\n",
    "\n",
    "Given that LightGBM and XGBoost are the top performing models, we will continue to develop these models further. We will start by tuning the hyperparameters of the models using Optuna, which is a library that applies Bayesian optimization to hyperparameter tuning. They adaptively explore the search space, focusing on more promising hyperparameter sets, which theoretically makes them more effective than RandomizedSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "from datetime import datetime\n",
    "from scipy.stats import uniform, randint\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "import optuna\n",
    "from optuna.storages import RDBStorage\n",
    "from optuna.pruners import HyperbandPruner\n",
    "from optuna.samplers import TPESampler\n",
    "import joblib\n",
    "\n",
    "# Define Optuna storage for resuming capability\n",
    "os.makedirs('saved_studies', exist_ok=True)\n",
    "storage = RDBStorage(url='sqlite:///saved_studies/optuna_study.db')\n",
    "\n",
    "# Define the XGBoost model and its hyperparameters\n",
    "xgb_model = XGBClassifier(random_state=42, eval_metric='auc', tree_method='hist', device='cuda')\n",
    "\n",
    "# Define the LightGBM model\n",
    "lgbm_model = LGBMClassifier(random_state=42, device='gpu')\n",
    "\n",
    "# Create pipeline for XGBoost\n",
    "pipeline_xgb = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', xgb_model)])\n",
    "\n",
    "# Create pipeline for LightGBM\n",
    "pipeline_lgbm = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', lgbm_model)])\n",
    "\n",
    "# Define Stratified K-Fold Cross-Validation\n",
    "stratified_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Optuna objective function for XGBoost\n",
    "def objective_xgb(trial):\n",
    "    params = {\n",
    "        'classifier__n_estimators': trial.suggest_int('classifier__n_estimators', 50, 2000),\n",
    "        'classifier__learning_rate': trial.suggest_float('classifier__learning_rate', 0.001, 0.5, log=True),\n",
    "        'classifier__max_depth': trial.suggest_int('classifier__max_depth', 3, 30),\n",
    "        'classifier__min_child_weight': trial.suggest_int('classifier__min_child_weight', 1, 20),\n",
    "        'classifier__gamma': trial.suggest_float('classifier__gamma', 0, 10),\n",
    "        'classifier__subsample': trial.suggest_float('classifier__subsample', 0.5, 1.0),\n",
    "        'classifier__colsample_bytree': trial.suggest_float('classifier__colsample_bytree', 0.5, 1.0),\n",
    "        'classifier__colsample_bylevel': trial.suggest_float('classifier__colsample_bylevel', 0.5, 1.0),\n",
    "        'classifier__colsample_bynode': trial.suggest_float('classifier__colsample_bynode', 0.5, 1.0),\n",
    "        'classifier__reg_alpha': trial.suggest_float('classifier__reg_alpha', 1e-3, 20.0, log=True),\n",
    "        'classifier__reg_lambda': trial.suggest_float('classifier__reg_lambda', 1e-3, 20.0, log=True),\n",
    "        'classifier__scale_pos_weight': trial.suggest_float('classifier__scale_pos_weight', 1, 20),\n",
    "        'classifier__max_delta_step': trial.suggest_int('classifier__max_delta_step', 0, 20),\n",
    "        'classifier__objective': trial.suggest_categorical('classifier__objective', ['binary:logistic']),\n",
    "        'classifier__grow_policy': trial.suggest_categorical('classifier__grow_policy', ['depthwise', 'lossguide']),\n",
    "        'classifier__max_bin': trial.suggest_int('classifier__max_bin', 128, 1024),\n",
    "        'classifier__learning_rate_decay_factor': trial.suggest_float('classifier__learning_rate_decay_factor', 0.1, 1.0),\n",
    "        'classifier__num_boost_round': trial.suggest_int('classifier__num_boost_round', 100, 2000),\n",
    "        'classifier__tree_method': trial.suggest_categorical('classifier__tree_method', ['gpu_hist']),\n",
    "        'classifier__booster': trial.suggest_categorical('classifier__booster', ['gbtree', 'gblinear', 'dart']),\n",
    "        'classifier__lambda_bias': trial.suggest_float('classifier__lambda_bias', 0.0, 10.0),\n",
    "        'classifier__monotone_constraints': trial.suggest_categorical('classifier__monotone_constraints', ['()', '(0, 0, 0)', '(1, 0, -1)', '(1, -1, 1)']),\n",
    "        'classifier__interaction_constraints': trial.suggest_categorical('classifier__interaction_constraints', ['()', '(0, 1)', '(1, 2, 3)', '(1, 2)']),\n",
    "        'classifier__num_parallel_tree': trial.suggest_int('classifier__num_parallel_tree', 1, 20),\n",
    "        'classifier__max_leaves': trial.suggest_int('classifier__max_leaves', 0, 200),\n",
    "        'classifier__sampling_method': trial.suggest_categorical('classifier__sampling_method', ['uniform', 'gradient_based']),\n",
    "        'classifier__alpha': trial.suggest_float('classifier__alpha', 0.0, 20.0),\n",
    "        'classifier__lambda': trial.suggest_float('classifier__lambda', 0.0, 20.0),\n",
    "        'classifier__max_cat_to_onehot': trial.suggest_int('classifier__max_cat_to_onehot', 1, 200),\n",
    "        'classifier__predictor': trial.suggest_categorical('classifier__predictor', ['gpu_predictor']),\n",
    "        'classifier__single_precision_histogram': trial.suggest_categorical('classifier__single_precision_histogram', [True, False]),\n",
    "        'classifier__objective_sample_rate': trial.suggest_float('classifier__objective_sample_rate', 0.1, 1.0),\n",
    "        'classifier__max_cat_threshold': trial.suggest_int('classifier__max_cat_threshold', 1, 128),\n",
    "        'classifier__refresh_leaf': trial.suggest_categorical('classifier__refresh_leaf', [True, False]),\n",
    "        'classifier__process_type': trial.suggest_categorical('classifier__process_type', ['default', 'update']),\n",
    "        'classifier__updater': trial.suggest_categorical('classifier__updater', ['grow_gpu_hist']),\n",
    "        'classifier__learning_rate_decay': trial.suggest_categorical('classifier__learning_rate_decay', [True, False]),\n",
    "        'classifier__early_stopping_rounds': trial.suggest_int('classifier__early_stopping_rounds', 10, 100),\n",
    "    }\n",
    "    \n",
    "    pipeline_xgb.set_params(**params)\n",
    "    scores = []\n",
    "    start_time = time.time()\n",
    "    for fold, (train_idx, val_idx) in enumerate(stratified_cv.split(X_train, y_train)):\n",
    "        fold_start_time = time.time()\n",
    "        print(f\"\\n--- Starting fold {fold + 1} for XGBoost ---\\n\")\n",
    "        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "        pipeline_xgb.fit(X_tr, y_tr)\n",
    "        score = pipeline_xgb.score(X_val, y_val)\n",
    "        scores.append(score)\n",
    "        fold_end_time = time.time()\n",
    "        fold_duration = fold_end_time - fold_start_time\n",
    "        print(f\"--- Finished fold {fold + 1} for XGBoost in {fold_duration:.2f} seconds ---\\n\")\n",
    "        # Estimate remaining time for folds\n",
    "        remaining_folds = stratified_cv.get_n_splits() - (fold + 1)\n",
    "        eta_folds = remaining_folds * fold_duration\n",
    "        print(f\"Estimated time remaining for current trial: {eta_folds:.2f} seconds\\n\")\n",
    "    end_time = time.time()\n",
    "    trial_duration = end_time - start_time\n",
    "    print(f\"\\n--- Completed all folds for XGBoost in {trial_duration:.2f} seconds ---\\n\")\n",
    "    return sum(scores) / len(scores)\n",
    "\n",
    "# Define Optuna study with HyperbandPruner and TPESampler\n",
    "sampler = TPESampler()\n",
    "pruner = HyperbandPruner()\n",
    "\n",
    "# Optimize XGBoost using Optuna\n",
    "study_xgb = optuna.create_study(direction='maximize', storage=storage, study_name='xgboost_study', load_if_exists=True, sampler=sampler, pruner=pruner)\n",
    "print(\"\\n--- Starting Optuna optimization for XGBoost ---\\n\")\n",
    "total_trials = 200\n",
    "start_time = time.time()\n",
    "for trial_idx in range(total_trials):\n",
    "    trial_start_time = time.time()\n",
    "    study_xgb.optimize(objective_xgb, n_trials=1)\n",
    "    # Save intermediate model after each trial\n",
    "    current_datetime = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    intermediate_xgb_filename = f\"saved_models/XGBoost_trial_{trial_idx + 1}_{current_datetime}.joblib\"\n",
    "    print(f\"Saving intermediate XGBoost model for trial {trial_idx + 1} as {intermediate_xgb_filename}...\\n\")\n",
    "    joblib.dump(pipeline_xgb, intermediate_xgb_filename)\n",
    "    print(f\"Intermediate XGBoost model for trial {trial_idx + 1} saved successfully as {intermediate_xgb_filename}.\\n\")\n",
    "    trial_end_time = time.time()\n",
    "    trial_duration = trial_end_time - trial_start_time\n",
    "    elapsed_time = trial_end_time - start_time\n",
    "    remaining_trials = total_trials - (trial_idx + 1)\n",
    "    eta_trials = remaining_trials * trial_duration\n",
    "    print(f\"\\n--- Finished trial {trial_idx + 1}/{total_trials} for XGBoost in {trial_duration:.2f} seconds ---\\n\")\n",
    "    print(f\"Elapsed time: {elapsed_time:.2f} seconds. Estimated time remaining for all trials: {eta_trials:.2f} seconds\\n\")\n",
    "end_time = time.time()\n",
    "print(f\"\\n--- Finished Optuna optimization for XGBoost in {end_time - start_time:.2f} seconds ---\\n\")\n",
    "\n",
    "# Save the best XGBoost model\n",
    "xgb_best_params = study_xgb.best_params\n",
    "pipeline_xgb.set_params(**xgb_best_params)\n",
    "pipeline_xgb.fit(X_train, y_train)\n",
    "current_datetime = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "xgb_filename = f\"saved_models/XGBoost_optuna_{current_datetime}.joblib\"\n",
    "print(f\"Saving best Optuna XGBoost model as {xgb_filename}...\\n\")\n",
    "joblib.dump(pipeline_xgb, xgb_filename)\n",
    "print(f\"Best Optuna XGBoost model saved successfully as {xgb_filename}.\\n\")\n",
    "\n",
    "# Optuna objective function for LightGBM\n",
    "def objective_lgbm(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 1000),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.5, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', -1, 15),  # Use -1 for no limit on depth\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 150),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'min_split_gain': trial.suggest_float('min_split_gain', 0.0, 1.0),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'subsample_freq': trial.suggest_int('subsample_freq', 0, 10),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-3, 10.0, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-3, 10.0, log=True),\n",
    "        'scale_pos_weight': trial.suggest_float('scale_pos_weight', 1, 10),\n",
    "        'boosting_type': 'gbdt',  # For GPU, it is common to use 'gbdt'\n",
    "        'device': 'gpu',  # This will enable GPU usage\n",
    "        'objective': trial.suggest_categorical('objective', ['binary', 'regression', 'multiclass']),\n",
    "        'max_bin': trial.suggest_int('max_bin', 128, 512),  # Typically, a higher value is recommended for GPU\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.5, 1.0),\n",
    "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.5, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 10),\n",
    "        'learning_rate_decay_factor': trial.suggest_float('learning_rate_decay_factor', 0.1, 1.0),\n",
    "        'num_boost_round': trial.suggest_int('num_boost_round', 100, 1000),\n",
    "        'early_stopping_round': trial.suggest_int('early_stopping_round', 10, 50),  # Optional\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 20, 100),  # Often used for regularization\n",
    "        'lambda_l1': trial.suggest_float('lambda_l1', 0, 10),  # L1 regularization\n",
    "        'lambda_l2': trial.suggest_float('lambda_l2', 0, 10),  # L2 regularization\n",
    "        'top_rate': trial.suggest_float('top_rate', 0.1, 0.5),  # Used when boosting_type='goss'\n",
    "        'other_rate': trial.suggest_float('other_rate', 0.1, 0.5),  # Used when boosting_type='goss'\n",
    "    }\n",
    "\n",
    "\n",
    "    pipeline_lgbm.set_params(**params)\n",
    "    scores = []\n",
    "    start_time = time.time()\n",
    "    for fold, (train_idx, val_idx) in enumerate(stratified_cv.split(X_train, y_train)):\n",
    "        fold_start_time = time.time()\n",
    "        print(f\"\\n--- Starting fold {fold + 1} for LightGBM ---\\n\")\n",
    "        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "        pipeline_lgbm.fit(X_tr, y_tr)\n",
    "        score = pipeline_lgbm.score(X_val, y_val)\n",
    "        scores.append(score)\n",
    "        fold_end_time = time.time()\n",
    "        fold_duration = fold_end_time - fold_start_time\n",
    "        print(f\"--- Finished fold {fold + 1} for LightGBM in {fold_duration:.2f} seconds ---\\n\")\n",
    "        # Estimate remaining time for folds\n",
    "        remaining_folds = stratified_cv.get_n_splits() - (fold + 1)\n",
    "        eta_folds = remaining_folds * fold_duration\n",
    "        print(f\"Estimated time remaining for current trial: {eta_folds:.2f} seconds\\n\")\n",
    "    end_time = time.time()\n",
    "    trial_duration = end_time - start_time\n",
    "    print(f\"\\n--- Completed all folds for LightGBM in {trial_duration:.2f} seconds ---\\n\")\n",
    "    return sum(scores) / len(scores)\n",
    "\n",
    "# Optimize LightGBM using Optuna\n",
    "study_lgbm = optuna.create_study(direction='maximize', storage=storage, study_name='lgbm_study', load_if_exists=True, sampler=sampler, pruner=pruner)\n",
    "print(\"\\n--- Starting Optuna optimization for LightGBM ---\\n\")\n",
    "total_trials = 200\n",
    "start_time = time.time()\n",
    "for trial_idx in range(total_trials):\n",
    "    trial_start_time = time.time()\n",
    "    study_lgbm.optimize(objective_lgbm, n_trials=1)\n",
    "    # Save intermediate model after each trial\n",
    "    current_datetime = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    intermediate_lgbm_filename = f\"saved_models/LightGBM_trial_{trial_idx + 1}_{current_datetime}.joblib\"\n",
    "    print(f\"Saving intermediate LightGBM model for trial {trial_idx + 1} as {intermediate_lgbm_filename}...\\n\")\n",
    "    joblib.dump(pipeline_lgbm, intermediate_lgbm_filename)\n",
    "    print(f\"Intermediate LightGBM model for trial {trial_idx + 1} saved successfully as {intermediate_lgbm_filename}.\\n\")\n",
    "    trial_end_time = time.time()\n",
    "    trial_duration = trial_end_time - trial_start_time\n",
    "    elapsed_time = trial_end_time - start_time\n",
    "    remaining_trials = total_trials - (trial_idx + 1)\n",
    "    eta_trials = remaining_trials * trial_duration\n",
    "    print(f\"\\n--- Finished trial {trial_idx + 1}/{total_trials} for LightGBM in {trial_duration:.2f} seconds ---\\n\")\n",
    "    print(f\"Elapsed time: {elapsed_time:.2f} seconds. Estimated time remaining for all trials: {eta_trials:.2f} seconds\\n\")\n",
    "end_time = time.time()\n",
    "print(f\"\\n--- Finished Optuna optimization for LightGBM in {end_time - start_time:.2f} seconds ---\\n\")\n",
    "\n",
    "# Save the best LightGBM model\n",
    "lgbm_best_params = study_lgbm.best_params\n",
    "pipeline_lgbm.set_params(**lgbm_best_params)\n",
    "pipeline_lgbm.fit(X_train, y_train)\n",
    "current_datetime = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "lgbm_filename = f\"saved_models/LightGBM_optuna_{current_datetime}.joblib\"\n",
    "print(f\"Saving best Optuna LightGBM model as {lgbm_filename}...\\n\")\n",
    "joblib.dump(pipeline_lgbm, lgbm_filename)\n",
    "print(f\"Best Optuna LightGBM model saved successfully as {lgbm_filename}.\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we evaluate the model on the training data. This gives:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ruibin: TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Test data evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the best model\n",
    "y_pred = best_classifier.predict(X_test)\n",
    "y_pred_proba = best_classifier.predict_proba(X_test)[:, 1] if hasattr(best_model_name.named_steps['classifier'], 'predict_proba') else y_pred\n",
    "\n",
    "# Print the best model and its parameters\n",
    "print(f\"\\nBest Model: {best_model_name}\")\n",
    "print(f\"Best Cross-Validation AUC Score: {best_score:.4f}\")\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Calculate and print AUC score on the test set\n",
    "auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "print(f\"AUC Score on Test Set: {auc_score:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bank",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
