{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "As the world is moving towards ubiquitous digitization in the financial sector, the risk of fraud grows faster than ever, posing significant challenges to both financial instutions and customers. As a result, the need for robust fraud detection systems capable of identifying and mitigating fraudulent activities is more important than ever.\n",
    "\n",
    "## Project Description\n",
    "This notebook aims to provide a comprehensive exploratory data analysis on the Bank Fraud Detection Base dataset, published at NeurIPS 2022.\n",
    "\n",
    "## Dataset Description\n",
    "The dataset is available at https://www.kaggle.com/datasets/sgpjesus/bank-account-fraud-dataset-neurips-2022/data.\n",
    "\n",
    "This synthetic tabular dataset comprises 1M instances, where each instance represents a credit card application. The dataset contains 31 features and a corresponding binary target variable indicating whether the application is fraudulent or not. The features cover various information associated with the applicant or the application. The dataset contains a combination of numerical and categorical features, and there are no missing values in the dataset. The dataset is highly imbalanced, with only ~1% of the instances labeled as fraudulent. The dataset is also generated based off real-world data to protect the privacy of potential applicants.\n",
    "\n",
    "A detailed description of the dataset can be found on https://github.com/feedzai/bank-account-fraud/blob/main/documents/datasheet.pdf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "\n",
    "# Set the maximum number of columns and rows to display\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors\n",
    "\n",
    "# Better visualizations for colorblind readers\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "sns.set_palette('colorblind')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "total_df = pd.read_csv('./Data/Base.csv')\n",
    "\n",
    "# Define features and target\n",
    "X = total_df.drop(columns='fraud_bool')\n",
    "y = total_df['fraud_bool']\n",
    "\n",
    "# Perform stratified split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "train = pd.concat([X_train, y_train], axis=1).copy()\n",
    "test = pd.concat([X_test, y_test], axis=1).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "\n",
    "## Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Target: 'fraud_bool'\")\n",
    "print(f\"Data type: {y_train.dtype}\")\n",
    "print(f\"Unique values: {y_train.dropna().unique()}\")\n",
    "print(f\"NaN values: {y_train.isna().sum()}\")\n",
    "print(f\"Null values: {y_train.isnull().sum()}\")\n",
    "\n",
    "# Get count and distribution\n",
    "count_distribution = y_train.value_counts()\n",
    "proportion_distribution = y_train.value_counts(normalize=True)\n",
    "\n",
    "print(\"\\nCount and Distribution of 'fraud_bool':\")\n",
    "for value in count_distribution.index:\n",
    "    count = count_distribution[value]\n",
    "    proportion = proportion_distribution[value]\n",
    "    print(f\"Value {value}: {count} ({proportion:.2%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shows the first 5 observations of the training data\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_feats = X_train.select_dtypes(include='number').columns\n",
    "cat_feats = X_train.select_dtypes(exclude='number').columns\n",
    "\n",
    "thresh = 13\n",
    "\n",
    "cont_feats = []\n",
    "disc_feats = []\n",
    "\n",
    "for feat in num_feats:\n",
    "    if total_df[feat].nunique() >= thresh:\n",
    "        cont_feats.append(feat)\n",
    "    else:\n",
    "        disc_feats.append(feat)\n",
    "\n",
    "print(\"Total Features:\", X_train.shape[1])\n",
    "print(\"\\nContinuous Features ({}): {}\".format(len(cont_feats), cont_feats))\n",
    "print(\"\\nDiscrete Features ({}): {}\".format(len(disc_feats), disc_feats))\n",
    "print(\"\\nCategorical Features ({}): {}\".format(len(cat_feats), cat_feats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The datasheet details that the following categories can be negative to represent missing values\n",
    "cols_missing= [\n",
    "    'prev_address_months_count', 'current_address_months_count',\n",
    "    'bank_months_count', 'session_length_in_minutes',\n",
    "    'device_distinct_emails_8w', 'intended_balcon_amount'\n",
    "]\n",
    "\n",
    "# Replace all negative values with NaN\n",
    "X_train[cols_missing] = X_train[cols_missing].mask(X_train[cols_missing] < 0, np.nan)\n",
    "\n",
    "# Calculate missing values percentage and display as a table\n",
    "missing_values = (X_train.isna().sum() / len(X_train) * 100).loc[lambda x: x > 0]\n",
    "missing_table = pd.DataFrame(missing_values, columns=[\"Missing %\"]).sort_values(by=\"Missing %\")\n",
    "\n",
    "# Print the missing values table\n",
    "print(\"Missing Values Table:\\n\", missing_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In-depth Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_analysis(feat, X_train, y_train, cont_feats, disc_feats):\n",
    "    def display_summary(summary):\n",
    "        return display(summary)\n",
    "\n",
    "    # Summary for continuous features\n",
    "    def cont_summary(feat):\n",
    "        columns = ['dtype', 'count', 'unique', 'top_value_counts', 'missing_count',\n",
    "                   'missing_percentage', 'mean', 'std', 'min', 'median', 'max']\n",
    "        summary = pd.DataFrame(index=[feat], columns=columns, dtype=float)\n",
    "        col = X_train[feat].copy()\n",
    "        summary.loc[feat, ['count', 'mean', 'std', 'min', 'median', 'max']] = col.describe(percentiles=[.5]).values.transpose()\n",
    "        summary.loc[feat, 'unique'] = col.nunique()\n",
    "        summary.loc[feat, 'missing_count'] = col.isnull().sum()\n",
    "        summary.loc[feat, 'missing_percentage'] = col.isnull().sum() / len(col) * 100\n",
    "        int_cols = ['count', 'unique', 'missing_count']\n",
    "        summary[int_cols] = summary[int_cols].astype(int)\n",
    "        summary = summary.round(2).astype(str)\n",
    "        value_counts = X_train[feat].value_counts().head(3)\n",
    "        value_counts.index = value_counts.index.astype(float).to_numpy().round(2)\n",
    "        summary.loc[feat, 'top_value_counts'] = str(value_counts.to_dict())\n",
    "        summary.loc[feat, 'dtype'] = col.dtypes\n",
    "        return display_summary(summary)\n",
    "\n",
    "    # Plots for continuous features\n",
    "    def cont_plots(feat, bins='auto'):\n",
    "        # Sample the data to a smaller size for resource-intensive plots\n",
    "        sample_size = min(10000, len(X_train))\n",
    "        X_train_sample = X_train.sample(n=sample_size, random_state=42)\n",
    "        y_train_sample = y_train.loc[X_train_sample.index]\n",
    "\n",
    "        n_cols = 7\n",
    "        fig, axes = plt.subplots(1, n_cols, figsize=(6.4 * n_cols, 4.8))\n",
    "        sns.histplot(data=X_train, x=feat, bins=bins, ax=axes[0])\n",
    "        sns.boxplot(data=X_train, x=feat, y=y_train, ax=axes[1], orient='h')\n",
    "        sns.kdeplot(data=X_train, x=feat, hue=y_train, fill=True, common_norm=False, ax=axes[2])\n",
    "        sns.violinplot(data=X_train_sample, x=feat, y=y_train_sample, ax=axes[3], orient='h')\n",
    "        sns.stripplot(data=X_train_sample, x=feat, y=y_train_sample, ax=axes[4], orient='h', jitter=True)\n",
    "        sns.swarmplot(data=X_train_sample, x=feat, y=y_train_sample, ax=axes[5], orient='h')\n",
    "        sns.boxenplot(data=X_train_sample, x=feat, y=y_train_sample, ax=axes[6], orient='h')\n",
    "        axes[0].title.set_text('Histogram')\n",
    "        axes[1].title.set_text('Box Plots')\n",
    "        axes[2].title.set_text('KDE Plots')\n",
    "        axes[3].title.set_text('Violin Plot')\n",
    "        axes[4].title.set_text('Strip Plot')\n",
    "        axes[5].title.set_text('Swarm Plot')\n",
    "        axes[6].title.set_text('Boxen Plot')\n",
    "        fig.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # Summary for discrete features\n",
    "    def disc_summary(feat):\n",
    "        columns = ['dtype', 'count', 'unique', 'missing_count', 'missing_percentage', 'mean', 'std', 'min', 'median', 'max', 'cv']\n",
    "        summary = pd.DataFrame(index=[feat], columns=columns, dtype=float)\n",
    "        col = X_train[feat].copy()\n",
    "        summary.loc[feat, ['count', 'mean', 'std', 'min', 'median', 'max']] = col.describe(percentiles=[.5]).values.transpose()\n",
    "        summary.loc[feat, 'unique'] = col.nunique()\n",
    "        summary.loc[feat, 'cv'] = np.NaN if not col.mean() else col.std() / col.mean()\n",
    "        summary.loc[feat, 'missing_count'] = col.isnull().sum()\n",
    "        summary.loc[feat, 'missing_percentage'] = col.isnull().sum() / len(col) * 100\n",
    "        int_cols = ['count', 'unique', 'missing_count']\n",
    "        summary[int_cols] = summary[int_cols].astype(int)\n",
    "        summary = summary.round(2).astype(str)\n",
    "        summary.loc[feat, 'dtype'] = col.dtypes\n",
    "        return display_summary(summary)\n",
    "\n",
    "    # Plots for discrete features\n",
    "    def disc_plots(feat):\n",
    "        col = X_train[feat].copy()\n",
    "        sample_size = min(10000, len(X_train))\n",
    "        X_train_sample = X_train.sample(n=sample_size, random_state=42)\n",
    "        y_train_sample = y_train.loc[X_train_sample.index]\n",
    "\n",
    "        n_cols = 5\n",
    "        fig, axes = plt.subplots(1, n_cols, figsize=(6.4 * n_cols, 4.8))\n",
    "        unique_values = col.dropna().unique()\n",
    "        unique_values.sort()\n",
    "        val_counts = col.dropna().value_counts()\n",
    "        val_counts = val_counts.reindex(unique_values)\n",
    "        val_counts_pct = val_counts / len(col) * 100\n",
    "        sns.countplot(x=col, order=unique_values, ax=axes[0])\n",
    "        axes[0].xaxis.grid(False)\n",
    "        lp_thresh = 1\n",
    "        for i, p in enumerate(axes[0].patches):\n",
    "            pct = val_counts_pct.iloc[i]\n",
    "            axes[0].annotate(f'{pct:.2f}%', (p.get_x() + p.get_width() / 2., p.get_height()), ha='center', va='bottom', xytext=(0, 0), textcoords='offset points')\n",
    "            if pct < lp_thresh:\n",
    "                axes[0].annotate(val_counts.iloc[i], (p.get_x() + p.get_width() / 2., p.get_height()), ha='center', va='bottom', xytext=(0, 10), textcoords='offset points', color='red')\n",
    "        df = pd.concat([X_train, y_train], axis=1).groupby(feat)[y_train.name].mean() * 100\n",
    "        df = df.reindex(unique_values)\n",
    "        sns.barplot(x=df.index, y=df.values, ax=axes[1])\n",
    "        sns.violinplot(data=X_train_sample, x=feat, y=y_train_sample, ax=axes[2])\n",
    "        sns.swarmplot(data=X_train_sample, x=feat, y=y_train_sample, ax=axes[3])\n",
    "        sns.boxenplot(data=X_train_sample, x=feat, y=y_train_sample, ax=axes[4])\n",
    "        axes[1].set_ylabel('Fraud %')\n",
    "        axes[1].xaxis.grid(False)\n",
    "        axes[2].title.set_text('Violin Plot')\n",
    "        axes[3].title.set_text('Swarm Plot')\n",
    "        axes[4].title.set_text('Boxen Plot')\n",
    "        fig.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # Summary for categorical features\n",
    "    def cat_summary(feat):\n",
    "        columns = ['dtype', 'count', 'unique', 'missing_count', 'missing_percentage']\n",
    "        summary = pd.DataFrame(index=[feat], columns=columns, dtype=float)\n",
    "        col = X_train[feat].copy()\n",
    "        summary.loc[feat, 'count'] = col.count()\n",
    "        summary.loc[feat, 'unique'] = col.nunique()\n",
    "        summary.loc[feat, 'missing_count'] = col.isnull().sum()\n",
    "        summary.loc[feat, 'missing_percentage'] = col.isnull().sum() / len(col) * 100\n",
    "        int_cols = ['count', 'unique', 'missing_count']\n",
    "        summary[int_cols] = summary[int_cols].astype(int)\n",
    "        summary = summary.round(2).astype(str)\n",
    "        summary.loc[feat, 'dtype'] = col.dtypes\n",
    "        return display_summary(summary)\n",
    "\n",
    "    # Plots for categorical features\n",
    "    def cat_plots(feat):\n",
    "        col = X_train[feat].copy()\n",
    "        sample_size = min(10000, len(X_train))\n",
    "        X_train_sample = X_train.sample(n=sample_size, random_state=42)\n",
    "        y_train_sample = y_train.loc[X_train_sample.index]\n",
    "\n",
    "        n_cols = 5\n",
    "        fig, axes = plt.subplots(1, n_cols, figsize=(6.4 * n_cols, 4.8))\n",
    "        val_counts = col.dropna().value_counts()\n",
    "        unique_values = val_counts.index\n",
    "        sns.countplot(x=col, order=unique_values, ax=axes[0])\n",
    "        axes[0].xaxis.grid(False)\n",
    "        val_counts_pct = val_counts / len(col) * 100\n",
    "        lp_thresh = 1\n",
    "        for i, p in enumerate(axes[0].patches):\n",
    "            pct = val_counts_pct.iloc[i]\n",
    "            axes[0].annotate(f'{pct:.2f}%', (p.get_x() + p.get_width() / 2., p.get_height()), ha='center', va='bottom', xytext=(0, 0), textcoords='offset points')\n",
    "            if pct < lp_thresh:\n",
    "                axes[0].annotate(val_counts.iloc[i], (p.get_x() + p.get_width() / 2., p.get_height()), ha='center', va='bottom', xytext=(0, 10), textcoords='offset points', color='red')\n",
    "        df = pd.concat([X_train, y_train], axis=1).groupby(feat)[y_train.name].mean() * 100\n",
    "        sns.barplot(x=df.index, y=df.values, order=unique_values, ax=axes[1])\n",
    "        sns.violinplot(data=X_train_sample, x=feat, y=y_train_sample, ax=axes[2])\n",
    "        sns.swarmplot(data=X_train_sample, x=feat, y=y_train_sample, ax=axes[3])\n",
    "        sns.boxenplot(data=X_train_sample, x=feat, y=y_train_sample, ax=axes[4])\n",
    "        axes[1].set_ylabel('Fraud %')\n",
    "        axes[1].xaxis.grid(False)\n",
    "        axes[2].title.set_text('Violin Plot')\n",
    "        axes[3].title.set_text('Swarm Plot')\n",
    "        axes[4].title.set_text('Boxen Plot')\n",
    "        fig.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # Plot for missing flag associated with a feature\n",
    "    def missing_flag_plot(feat):\n",
    "        col = X_train[feat].isnull().astype(int)\n",
    "        if not col.sum():\n",
    "            return\n",
    "        df = (pd.concat([col, y_train], axis=1).groupby(feat).mean() * 100).reset_index()\n",
    "        cols = [f'MISSING_{feat}', 'Fraud %']\n",
    "        df.columns = cols\n",
    "        fig = plt.figure(figsize=(6.4, 4.8))\n",
    "        ax = sns.barplot(data=df, x=cols[0], y=cols[1])\n",
    "        fig.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # Joint Plot for analyzing relationships between features\n",
    "    if feat in cont_feats:\n",
    "        cont_summary(feat)\n",
    "        cont_plots(feat)\n",
    "    elif feat in disc_feats:\n",
    "        disc_summary(feat)\n",
    "        disc_plots(feat)\n",
    "    else:\n",
    "        cat_summary(feat)\n",
    "        cat_plots(feat)\n",
    "    missing_flag_plot(feat)\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for feat in cont_feats:\n",
    "#     print(f\"\\033[1m Feature:\\033[0m '{feat}'\\n\")\n",
    "#     feature_analysis(feat, X_train, y_train, cont_feats, disc_feats)\n",
    "#     print('-'*45, '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for feat in disc_feats:\n",
    "#     print(f\"\\033[1m Feature:\\033[0m '{feat}'\\n\")\n",
    "#     feature_analysis(feat, X_train, y_train, cont_feats, disc_feats)\n",
    "#     print('-'*45, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for feat in cat_feats:\n",
    "#     print(f\"\\033[1m Feature:\\033[0m '{feat}'\\n\")\n",
    "#     feature_analysis(feat, X_train, y_train, cont_feats, disc_feats)\n",
    "#     print('-'*45, '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
