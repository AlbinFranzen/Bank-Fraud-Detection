{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "\n",
    "This notebook contains the exploratory data analysis for the bank fraud detection dataset. It is split into multiple sections being \n",
    "\n",
    "- Initial understanding of the data\n",
    "- Exploring the features individually (visualization/outliers)\n",
    "    - Numeric data\n",
    "    - Numerical categorical data\n",
    "    - Categoricla data\n",
    "- Exploring the features in relation to eachother (visualization/correlation)\n",
    "- Identify possible transformations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Initial understanding of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training data has 800000 rows and 32 columns.\n",
      "The testing data has 200000 rows and 32 columns.\n"
     ]
    }
   ],
   "source": [
    "# Data collection\n",
    "total_df = pd.read_csv('./Data/Base.csv')\n",
    "\n",
    "# Split the DataFrame into training and test sets using stratified sampling to maintain anomaly distribution\n",
    "train_df, test_df = train_test_split(total_df, test_size=0.2, stratify=total_df['fraud_bool'], random_state=42)\n",
    "\n",
    "# Validate the size of the data\n",
    "train_shape = train_df.shape\n",
    "test_shape = test_df.shape\n",
    "print(f\"The training data has {train_shape[0]} rows and {train_shape[1]} columns.\")\n",
    "print(f\"The testing data has {test_shape[0]} rows and {test_shape[1]} columns.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start the EDA by importing data from the Base.csv file and split this up into training and test data to avoid data leakage. The split is done using stratified sampling from the \"fraud_bool\" feature which preserves output distribution due to most likely unbalanced features. We can see that the data has 32 columns where the training data contains 80000 samples and the test data has 20000. Next we can have a quick look at what the dataframe looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fraud_bool</th>\n",
       "      <th>income</th>\n",
       "      <th>name_email_similarity</th>\n",
       "      <th>prev_address_months_count</th>\n",
       "      <th>current_address_months_count</th>\n",
       "      <th>customer_age</th>\n",
       "      <th>days_since_request</th>\n",
       "      <th>intended_balcon_amount</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>zip_count_4w</th>\n",
       "      <th>...</th>\n",
       "      <th>has_other_cards</th>\n",
       "      <th>proposed_credit_limit</th>\n",
       "      <th>foreign_request</th>\n",
       "      <th>source</th>\n",
       "      <th>session_length_in_minutes</th>\n",
       "      <th>device_os</th>\n",
       "      <th>keep_alive_session</th>\n",
       "      <th>device_distinct_emails_8w</th>\n",
       "      <th>device_fraud_count</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39111</th>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.229712</td>\n",
       "      <td>-1</td>\n",
       "      <td>63</td>\n",
       "      <td>50</td>\n",
       "      <td>0.024720</td>\n",
       "      <td>50.674001</td>\n",
       "      <td>AA</td>\n",
       "      <td>1305</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>3.580550</td>\n",
       "      <td>linux</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822700</th>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.928428</td>\n",
       "      <td>199</td>\n",
       "      <td>24</td>\n",
       "      <td>70</td>\n",
       "      <td>0.014153</td>\n",
       "      <td>15.631407</td>\n",
       "      <td>AA</td>\n",
       "      <td>833</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>7.087779</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914415</th>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.658630</td>\n",
       "      <td>95</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>0.045801</td>\n",
       "      <td>-1.410133</td>\n",
       "      <td>AB</td>\n",
       "      <td>237</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>0.547804</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581307</th>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.774858</td>\n",
       "      <td>-1</td>\n",
       "      <td>122</td>\n",
       "      <td>30</td>\n",
       "      <td>0.005569</td>\n",
       "      <td>-0.539938</td>\n",
       "      <td>AB</td>\n",
       "      <td>895</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>4.671407</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603136</th>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.993460</td>\n",
       "      <td>103</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>0.010832</td>\n",
       "      <td>-0.501067</td>\n",
       "      <td>AB</td>\n",
       "      <td>4105</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>INTERNET</td>\n",
       "      <td>9.293206</td>\n",
       "      <td>linux</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        fraud_bool  income  name_email_similarity  prev_address_months_count  \\\n",
       "39111            0     0.7               0.229712                         -1   \n",
       "822700           0     0.2               0.928428                        199   \n",
       "914415           0     0.1               0.658630                         95   \n",
       "581307           0     0.8               0.774858                         -1   \n",
       "603136           0     0.9               0.993460                        103   \n",
       "\n",
       "        current_address_months_count  customer_age  days_since_request  \\\n",
       "39111                             63            50            0.024720   \n",
       "822700                            24            70            0.014153   \n",
       "914415                             2            40            0.045801   \n",
       "581307                           122            30            0.005569   \n",
       "603136                             9            20            0.010832   \n",
       "\n",
       "        intended_balcon_amount payment_type  zip_count_4w  ...  \\\n",
       "39111                50.674001           AA          1305  ...   \n",
       "822700               15.631407           AA           833  ...   \n",
       "914415               -1.410133           AB           237  ...   \n",
       "581307               -0.539938           AB           895  ...   \n",
       "603136               -0.501067           AB          4105  ...   \n",
       "\n",
       "        has_other_cards  proposed_credit_limit  foreign_request    source  \\\n",
       "39111                 1                 1500.0                0  INTERNET   \n",
       "822700                0                  500.0                0  INTERNET   \n",
       "914415                0                  200.0                0  INTERNET   \n",
       "581307                1                  500.0                0  INTERNET   \n",
       "603136                1                  200.0                0  INTERNET   \n",
       "\n",
       "        session_length_in_minutes device_os  keep_alive_session  \\\n",
       "39111                    3.580550     linux                   0   \n",
       "822700                   7.087779     other                   1   \n",
       "914415                   0.547804     other                   1   \n",
       "581307                   4.671407     other                   1   \n",
       "603136                   9.293206     linux                   0   \n",
       "\n",
       "        device_distinct_emails_8w device_fraud_count  month  \n",
       "39111                           1                  0      0  \n",
       "822700                          1                  0      6  \n",
       "914415                          1                  0      7  \n",
       "581307                          1                  0      4  \n",
       "603136                          1                  0      4  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shows the first 5 observations of the training data\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we can see that the data consists of a target variable called fraud_bool along with many features which give information on whether a certain bank account is fraudulent. The name fraud_bool hints at it being a boolean feature so we can check the different possible outputs in the fraud_bool feature and their distribution by doing the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The unique values in the column are: 0, 1\n",
      "\n",
      "Distribution of the output variable:\n",
      "Value 0: 98.90%\n",
      "Value 1: 1.10%\n"
     ]
    }
   ],
   "source": [
    "# Find the unique values of fraud_bool and prints their distribution\n",
    "unique_outputs= train_df['fraud_bool'].unique()\n",
    "print(f\"The unique values in the column are: {', '.join(map(str, unique_outputs))}\")\n",
    "\n",
    "# Get the distribution of the fraud_bool\n",
    "distribution = df['fraud_bool'].value_counts(normalize=True)\n",
    "print(\"\\nDistribution of the output variable:\")\n",
    "for value, proportion in distribution.items():\n",
    "    print(f\"Value {value}: {proportion:.2%}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we see us that our problem is a binary classification problem because we only have two outputs 0 and 1. We also see that our data is highly imbalanced as 98.9% of the data is not fraudulent whereas 1.1% is a fraud. This will need to be taken into account for the preprocessing of the data. Moving on we can calculate the types of all of the features to determine what we are dealing with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 800000 entries, 39111 to 228494\n",
      "Data columns (total 32 columns):\n",
      " #   Column                            Non-Null Count   Dtype  \n",
      "---  ------                            --------------   -----  \n",
      " 0   fraud_bool                        800000 non-null  int64  \n",
      " 1   income                            800000 non-null  float64\n",
      " 2   name_email_similarity             800000 non-null  float64\n",
      " 3   prev_address_months_count         800000 non-null  int64  \n",
      " 4   current_address_months_count      800000 non-null  int64  \n",
      " 5   customer_age                      800000 non-null  int64  \n",
      " 6   days_since_request                800000 non-null  float64\n",
      " 7   intended_balcon_amount            800000 non-null  float64\n",
      " 8   payment_type                      800000 non-null  object \n",
      " 9   zip_count_4w                      800000 non-null  int64  \n",
      " 10  velocity_6h                       800000 non-null  float64\n",
      " 11  velocity_24h                      800000 non-null  float64\n",
      " 12  velocity_4w                       800000 non-null  float64\n",
      " 13  bank_branch_count_8w              800000 non-null  int64  \n",
      " 14  date_of_birth_distinct_emails_4w  800000 non-null  int64  \n",
      " 15  employment_status                 800000 non-null  object \n",
      " 16  credit_risk_score                 800000 non-null  int64  \n",
      " 17  email_is_free                     800000 non-null  int64  \n",
      " 18  housing_status                    800000 non-null  object \n",
      " 19  phone_home_valid                  800000 non-null  int64  \n",
      " 20  phone_mobile_valid                800000 non-null  int64  \n",
      " 21  bank_months_count                 800000 non-null  int64  \n",
      " 22  has_other_cards                   800000 non-null  int64  \n",
      " 23  proposed_credit_limit             800000 non-null  float64\n",
      " 24  foreign_request                   800000 non-null  int64  \n",
      " 25  source                            800000 non-null  object \n",
      " 26  session_length_in_minutes         800000 non-null  float64\n",
      " 27  device_os                         800000 non-null  object \n",
      " 28  keep_alive_session                800000 non-null  int64  \n",
      " 29  device_distinct_emails_8w         800000 non-null  int64  \n",
      " 30  device_fraud_count                800000 non-null  int64  \n",
      " 31  month                             800000 non-null  int64  \n",
      "dtypes: float64(9), int64(18), object(5)\n",
      "memory usage: 201.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# Print the column names, non-null count and datatype\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we get the information that we have no null features or missing features meaning that data imputation won't be necessary for our project. We have numerical catergorical features with the type \"int64\", numerical features with the type \"float64\" and a few categorical features with the type \"object\". Let's create 3 seperate dataframes for these different feature categories and study them seperately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate DataFrames based on column data types\n",
    "num_df = train_df.select_dtypes(include=['float64'])  # Numerical data \n",
    "numcat_df = train_df.select_dtypes(include=['int64'])  # Numerical categorical\n",
    "cat_df = train_df.select_dtypes(include=['object'])     # Categorical "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploring the features individually\n",
    "\n",
    "### 2.1 Numerical features\n",
    "\n",
    "We start by analysing the numerical features. The first thing we can check is the statistics of the data such as the mean and standard deviations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>income</th>\n",
       "      <th>name_email_similarity</th>\n",
       "      <th>days_since_request</th>\n",
       "      <th>intended_balcon_amount</th>\n",
       "      <th>velocity_6h</th>\n",
       "      <th>velocity_24h</th>\n",
       "      <th>velocity_4w</th>\n",
       "      <th>proposed_credit_limit</th>\n",
       "      <th>session_length_in_minutes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>800000.000000</td>\n",
       "      <td>800000.000000</td>\n",
       "      <td>8.000000e+05</td>\n",
       "      <td>800000.000000</td>\n",
       "      <td>800000.000000</td>\n",
       "      <td>800000.000000</td>\n",
       "      <td>800000.000000</td>\n",
       "      <td>800000.000000</td>\n",
       "      <td>800000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.562860</td>\n",
       "      <td>0.493798</td>\n",
       "      <td>1.024099e+00</td>\n",
       "      <td>8.665099</td>\n",
       "      <td>5664.020229</td>\n",
       "      <td>4770.234656</td>\n",
       "      <td>4856.003621</td>\n",
       "      <td>516.090400</td>\n",
       "      <td>7.549768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.290343</td>\n",
       "      <td>0.289099</td>\n",
       "      <td>5.377299e+00</td>\n",
       "      <td>20.232373</td>\n",
       "      <td>3009.677961</td>\n",
       "      <td>1479.503976</td>\n",
       "      <td>919.619696</td>\n",
       "      <td>487.736585</td>\n",
       "      <td>8.044859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>4.036860e-09</td>\n",
       "      <td>-15.530555</td>\n",
       "      <td>-170.603072</td>\n",
       "      <td>1320.283991</td>\n",
       "      <td>2825.748405</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.225325</td>\n",
       "      <td>7.181675e-03</td>\n",
       "      <td>-1.181143</td>\n",
       "      <td>3434.759967</td>\n",
       "      <td>3593.073983</td>\n",
       "      <td>4268.308917</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>3.104958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.492314</td>\n",
       "      <td>1.516505e-02</td>\n",
       "      <td>-0.829849</td>\n",
       "      <td>5316.302685</td>\n",
       "      <td>4750.803340</td>\n",
       "      <td>4913.542421</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>5.113827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.755595</td>\n",
       "      <td>2.631458e-02</td>\n",
       "      <td>5.074825</td>\n",
       "      <td>7680.990796</td>\n",
       "      <td>5753.115565</td>\n",
       "      <td>5487.683683</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>8.866801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>7.845690e+01</td>\n",
       "      <td>112.956928</td>\n",
       "      <td>16715.565404</td>\n",
       "      <td>9506.896596</td>\n",
       "      <td>6994.764201</td>\n",
       "      <td>2100.000000</td>\n",
       "      <td>85.899143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              income  name_email_similarity  days_since_request  \\\n",
       "count  800000.000000          800000.000000        8.000000e+05   \n",
       "mean        0.562860               0.493798        1.024099e+00   \n",
       "std         0.290343               0.289099        5.377299e+00   \n",
       "min         0.100000               0.000001        4.036860e-09   \n",
       "25%         0.300000               0.225325        7.181675e-03   \n",
       "50%         0.600000               0.492314        1.516505e-02   \n",
       "75%         0.800000               0.755595        2.631458e-02   \n",
       "max         0.900000               0.999999        7.845690e+01   \n",
       "\n",
       "       intended_balcon_amount    velocity_6h   velocity_24h    velocity_4w  \\\n",
       "count           800000.000000  800000.000000  800000.000000  800000.000000   \n",
       "mean                 8.665099    5664.020229    4770.234656    4856.003621   \n",
       "std                 20.232373    3009.677961    1479.503976     919.619696   \n",
       "min                -15.530555    -170.603072    1320.283991    2825.748405   \n",
       "25%                 -1.181143    3434.759967    3593.073983    4268.308917   \n",
       "50%                 -0.829849    5316.302685    4750.803340    4913.542421   \n",
       "75%                  5.074825    7680.990796    5753.115565    5487.683683   \n",
       "max                112.956928   16715.565404    9506.896596    6994.764201   \n",
       "\n",
       "       proposed_credit_limit  session_length_in_minutes  \n",
       "count          800000.000000              800000.000000  \n",
       "mean              516.090400                   7.549768  \n",
       "std               487.736585                   8.044859  \n",
       "min               190.000000                  -1.000000  \n",
       "25%               200.000000                   3.104958  \n",
       "50%               200.000000                   5.113827  \n",
       "75%               500.000000                   8.866801  \n",
       "max              2100.000000                  85.899143  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking the table above we can see that the features called velocity have a very high mean and that the feature proposed_credit_limit also is quite high. When reading the documentation about the dataset we learn that velocity is the average number of applications per hour during the stated time in the feature (velocity_6h is the last 6 hours). One can already speculate that perhaps looking 4 weeks back when averaging per hour won't be a necessary feature since it is over such a long time span that frauds will cancel out in the mix. Another noticiable thing is that the standard deviation of days_since_request is very large indicating that this feature could be close to a uniform distribution and probably also isn't relevant for our model. Another interesting aspect is that the minimum value of session_length_in_minutes is -1 which could mean that this value is a placeholder for something else since negative time isn't possible. Further analysis will need to be done on the features individually to determine proper transformations that should be done to the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Analyse the features one by one and visualise them with histograms and boxplots"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
