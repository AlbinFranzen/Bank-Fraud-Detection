{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "This jupyter notebook creates an sklearn pipeline for our data preprocessing. The steps that we need to follow are motivated by the EDA and are split into\n",
    "\n",
    "- Numerical features\n",
    "- High-cardinality categorical features\n",
    "- Low-cardinality categorical features\n",
    "- Boolean categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import Binarizer\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training data has 800000 rows and 32 columns.\n",
      "The testing data has 200000 rows and 32 columns.\n"
     ]
    }
   ],
   "source": [
    "# Data collection\n",
    "total_df = pd.read_csv('./Data/Base.csv')\n",
    "\n",
    "# Split the DataFrame into training and test sets using stratified sampling to maintain anomaly distribution\n",
    "train_df, test_df = train_test_split(total_df, test_size=0.2, stratify=total_df['fraud_bool'], random_state=42)\n",
    "\n",
    "# Validate the size of the data\n",
    "train_shape = train_df.shape\n",
    "test_shape = test_df.shape\n",
    "print(f\"The training data has {train_shape[0]} rows and {train_shape[1]} columns.\")\n",
    "print(f\"The testing data has {test_shape[0]} rows and {test_shape[1]} columns.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature transformations for numerical features\n",
    "\n",
    "The numerical features will be transformed as follows\n",
    "\n",
    "Name_email_similarity:\n",
    "- Convert into 5 bins, 4 with range 0.24 and 1 with range 0.04 (0.96-1)\n",
    "- There are no outliers\n",
    "\n",
    "Days_since_request:\n",
    "- Convert into 3 bins [0->Q2, Q2->Q3+1.5* IQR, Q3+1.5*IQR+]\n",
    "\n",
    "Intended_balcon_amount\n",
    "- Replace with boolean feature if positive account\n",
    "\n",
    "Velocity_6h, _24h, 4w\n",
    "- Remove all\n",
    "\n",
    "Session_length_in_minutes\n",
    "- Remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom transformer for binning 'name_email_similarity'\n",
    "class NameEmailSimilarityBinner(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.bin_edges = np.array([0.0, 0.24, 0.48, 0.72, 0.96, 1.0])\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.digitize(X.to_numpy().flatten(), bins=self.bin_edges, right=False).reshape(-1, 1)\n",
    "\n",
    "# Custom transformer for binning 'days_since_request'\n",
    "class DaysSinceRequestBinner(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        X_series = X.to_numpy().flatten()\n",
    "        self.Q2 = np.quantile(X_series, 0.5)\n",
    "        self.upper_fence = np.quantile(X_series, 0.75) + 1.5 * (np.quantile(X_series, 0.75) - np.quantile(X_series, 0.25))\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        bin_edges = np.array([-np.inf, self.Q2, self.upper_fence, np.inf])\n",
    "        return np.digitize(X.to_numpy().flatten(), bins=bin_edges, right=False).reshape(-1, 1)\n",
    "\n",
    "# Pipeline to drop velocity columns and apply transformations while keeping other columns\n",
    "numerical_preprocessor = Pipeline([\n",
    "    ('drop_velocity_columns', FunctionTransformer(lambda X: X.drop(columns=[\"velocity_6h\", \"velocity_24h\", \"velocity_4w\"]))),\n",
    "    ('transformer', ColumnTransformer([\n",
    "        ('name_email_similarity_binned', NameEmailSimilarityBinner(), ['name_email_similarity']),\n",
    "        ('days_since_request_binned', DaysSinceRequestBinner(), ['days_since_request']),\n",
    "        ('intended_balcon_amount_positive', Binarizer(threshold=0.0), ['intended_balcon_amount'])\n",
    "    ], remainder='passthrough'))  # Keep other columns as they are\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature transformations for high-cardinality categorical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature transformations for low-cardinality categorical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature transformations for boolean categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHOULD BE MOVED TO DATAPREPROCESSING?\n",
    "\n",
    "# One-hot encoding for categorical variables\n",
    "encoded_train_df = pd.get_dummies(train_df, columns=cat_df.columns, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHOULD BE MOVED TO DATAPREPROCESSING?\n",
    "\n",
    "# Apply log transformation\n",
    "for column in ['velocity_6h', 'velocity_24h', 'zip_count_4w']:\n",
    "    train_df[column] = np.log1p(train_df[column])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
